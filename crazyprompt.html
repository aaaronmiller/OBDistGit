<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>RAG Strategy Conversation</title>
    <style>
        body {
            font-family: 'Arial', sans-serif;
            line-height: 1.6;
            margin: 20px;
            background-color: #f4f4f9;
            color: #333;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #fff;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
        }
        .user-prompt {
            background-color: #e6f3ff;
            padding: 15px;
            margin-bottom: 20px;
            border-left: 5px solid #0066cc;
            border-radius: 5px;
        }
        .ai-response {
            background-color: #f0fff0;
            padding: 15px;
            margin-bottom: 20px;
            border-left: 5px solid #009900;
            border-radius: 5px;
        }
        h2 {
            color: #333;
            font-size: 1.5em;
            margin-bottom: 10px;
        }
        p {
            margin: 0 0 10px 0;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="user-prompt">
            <h2>User Prompt</h2>
            <p>Excellent. Now based on that data, please research additional alternative approaches or methodologies and determine if there is any additional resources or techniques that we can use for the completion of our process. Focus on our agentic task separation duties, the specific needs of processing PDF, Windows Word documents, AI transcriptions and output files, HTML, JavaScript, Markdown, CSS, Python, and PHP code, bash scripting. Audio files, video files, image files of various formats, and any other data set which might be embedded within our documents. Also, we need to be able to process Excel tables and PowerPoint presentations, YouTube videos in general, like how to take a YouTube video transcription and convert that into our proper format. Research papers, professional archive format style, handwritten notes in a non-formal style. Slideshows. Websites with interactive JavaScript content that shows, you know, multiple pages in a single page or horizontal sliders, vertical sliders, all the commonly used navigation techniques used on modern websites, file structure data, terminal output, screenshots from operating computers, application screenshots, news presentations, documentaries, movies, all of the ebook formats and online reading formats. Include specific directions for processing all of these according to a unified formula tailored to my uses. Perhaps this also necessitates the creation of an additional database or reference file for the descriptions of the flags we're using, the tags, and the tags we are using for various purposes, as well as our directory structure, and other architectural elements of the framework which we are implementing now. Final product will be applicable to general use by others and the system can be posted online or anywhere as well as additional refinements for my personal use as noted above. In general, those refinements can be applied to the methodology we just present globally. However, if there are specific use cases which do not seem to be fundamentally useful to other people, identify those and I can make the decision on whether or not the content is worthy of the global document or will just stay part of our own personal plan. Present said plan to me so that I can analyze it for errors or omissions and perform research necessary to ensure that the document you produce is comprehensive in nature and scope.</p>
            <p>Evaluate the documents open next to this command and determine from them the optimal strategy for converting text documents into markdown format suitable for agentic RAG retrieval. Crucially, this operation must include instructions on how to remove unneeded white space reformers. Reformat visual representations into an effective markdown version suitable for later retrieval by automated systems through database interaction and queries. Fulfill all of the technical challenges as described in the two papers on RAG and also properly identify locations within the document for optimal chunking and keyword tagging. The process steps involved are described in general in the document. However, I require a specific implementation tailored to the needs that I have associated with this; the requirement that this be specialized for not just documents in general, but for the conversion of documents created by AI utilizing the most recent standards. Critically, this involves the additional steps of identifying prompting cues used by the user in the creation of that document often provided in association with said document, as well as thinking behavior by the model and proper handling of the documents. In particular, I've noticed when copying and pasting documents produced by artificial intelligence that the section at the bottom where the sources are listed often looks okay on HTML because it dynamically resizes the icons into the proper size, but when placed into Obsidian or when used in an email, the icons are improperly displayed at their largest size and are heavily distorted as a result. Additionally, the formatting prohibits their display in a singular horizontal line. I end up with a large combination of vertical web addresses and their associated extra-large icons. Preferably, this would be reformatted prior to ingestion so that the format from markdown could later be cut and pasted into emails with relative ease. This would involve converting the icons to reference the specific 16 by 16 mini-sized version of the tag. Although this would later interact incorrectly with zooming and resizing of said document on portable devices, this flaw is a necessity given the use cases, which I've described is more important that I be able to cut and paste an email than it is for me to see the documents on multiple devices as I'm currently using a specific device STS document was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity.
All rights reserved. No reuse allowed without permission. device, a Mac OS laptop. And so this implementation is specific to my needs. Identify what these specifics are, which are reflected to my needs and which are of a more general nature. So this strategic approach can be adopted by others for their use as well. So specifically with the icons that can be addressed by defining the problem in both ways and the eventual user or whoever gets the document can decide how to approach it from there. The last critical element is the formatting of the negative space and the location of the chunking areas so that the chunking is properly done. The chunking needs to be oversized in its application so it's not sufficient to merely identify sections on a page, but rather location should be identified where the chunking process will, for instance, grab X mini characters before that point, or after that point, or maybe before and after that point, thereby creating the cohesive nature of the strategy. The chunking will be optimally formatted to always chunk the same size, I think. This will be either from the point of reference and then beyond to the extension and then maybe, maybe it's like you find the point that you want to chunk from, and then you go until you find a space. This sentence and, or a paragraph, and your character limit has not been hit for your chunking size, then maybe you grab it as a paragraph for the content-based RAG. And then you also grab a number of characters before and after the chunk to satisfy the needs of the boundary issues as stated; this facilitates automated retrieval of associated documentation by providing additional context for the object involved in the chunking. Perhaps this can also be tagged so the chunk can be separated into content and then content that's around that that used for just for the association part. Also, the conversion of the visual elements into representational needs to critically facilitate the retrieval through automated agent RAG. And thus, it's important that the visual and textual elements contained in the document be handled precisely. Research methodology used by others for conversion of bar graphs, circular wedge graphs, pie graphs, charts. And all sorts of the most popular visual media; include definitions for the top 20 kinds of most popular charts and visualizations used in presentations and documents. Finally, for visual imagery and audio imagery, I believe the best approach is probably to send the image to an outside, to another AI for categorization and tagging as well. So generate an optimal system prompt to append to any image that is sent out for RAG processing, similarly do that with the audio. Additionally, we may want to use tool use MCP servers like this in a similar way to process the charts and whatnot. This might aid in the functioning of the primary synthesis RAG agent. So that agent would be using sub-agents, but specialized tool use, each tool use can specially optimize for the classification step that they're involved with. This becomes a more cohesive pattern as the agentic implementation of the RAG now involves a subdivision of tasks and additional agentic behavior. This is done by defining the tool in question or the service in question, which is the tool, the specific tool use commands, and then crucially, the agentic system prompt associated with that tool use behavior. This will then, given a given inference application, it will not need to load up an additional session as the model will already be in memory, but it will spin up a second conversation using the model that's already in memory, and then we'll get that agentic request, along with the system prompt on how to instruct that agent to perform its duties. Those actions can be conducted in a parallel manner, such that the primary orchestrating agent need not await their completion prior to assessment of the next chunk. You divide this strategy into a holistic strategy that applies comprehensively to all of the data that I'm likely to ingest along with my specific key use cases. I have repeated myself several times in this. You don't need to take anything I've said as verbatim fact, make sure that you check online and do a comprehensive search of what additional other people are doing to solve the same problem. There's very good documentation on this already; utilize their work as a starting point and specialize it to my specific needs. Then let me know what you've done to modify that source document, if indeed that's the way you choose to approach it. Alternatively, you could investigate 10 or 20 of these sites and then synthesize 10 or 20 sites into a single cohesive document for the ultimate final output products.</p>
            <p>Final product will be applicable to general use by others and the system can be posted online or anywhere as well as additional refinements for my personal use as noted above. In general, those refinements can be applied to the methodology we just present globally. However, if there are specific use cases which do not seem to be fundamentally useful to other people, identify those and I can make the decision on whether or not the content is worthy of the global document or will just stay part of our own personal plan. Present said plan to me so that I can analyze it for errors or omissions and perform research necessary to ensure that the document you produce is comprehensive in nature and scope.</p>
            <p>Excellent. Additionally, I require a current preliminary version of our RAG approach, as I have many documents currently in production pipeline, and the sooner I can implement a RAG-specific analysis protocol on them the better. Give me something that I can just paste in a simple prompt to an AI agent along with the document to have it processed according to my needs so that I can begin to file my current and utilize documents and it will reduce work later in the process. Pay special attention to the chunking methodology, the handling of visual and textual data, especially to aid and facilitate its later ingestion by the RAG. And most importantly, the analysis and recording of AI conversational history and, critically, several of these issues are fundamentally addressed, primarily the issue of conversion of the resources used section below the thinking elements where AIs list their websites that they've visited for obtaining the information; that needs to be converted to small 16 by 16 icons from the existing size and formatted into a long horizontal row of small icons that can easily be stashed at the bottom of whatever document that it's in, rather than the current approach which is optimized for viewing on multiple devices of varying screen sizes. That's not a use case issue for me, and this is an exception specific to my needs and does not impact our global RAG strategy, but needs to be added as an additional appendix in addition to any other user-specific notes that are exclusive to my use case. Additionally, a comprehensive strategy for converting both screenshots and cut-and-paste screen to the AI conversational histories into our RAG pipeline processor needs to be addressed as well as historical elements. This step involves agentic analysis of the document, tagging of the different elements, and utilizing our defined methodology to prepare the document for ingestion into our database. Research other users' approaches and techniques for this, specifically where to chunk, how big a chunk this should be done. If chunking should be done in a multi-step approach, multiple sizes, individual words, sentences, etc. If so, include all this in our multi-step approach. But this is, remember, a synthesized and smaller version, just making sure that there's nothing missed from our other version. If all that is included already, all good. If not, you may enhance and revise the original document with this additional information. Make sure you do a comprehensive search online of the most commonly used and effective techniques, as there's a lot of research on this already and we don't want to be reinventing the wheel. Be comprehensive in your analysis; if there's a data structure or method that I've outlined, do not take that as a functional mandate. If you can produce an alternative process or structure, which is superior to that offered by the user, go ahead and use that instead. Just explain your use, change, and alteration so that the user can understand what has been modified against what they described.</p>
            <p>Next, give me instructions for how to create and implement the above strategy utilizing brew code with Visual Studio Code. I believe this is our primary tool for this initially, although we can utilize others. The diverse MCP library of tools we have access to within brew makes this especially easy. Don't forget to mandate using the terminal commands to identify file dates and times associated with their creation, their modification, when ingesting documents. Do we have a comprehensive metadata folder or file for every ingested document? That's probably a good idea because then we can include content analysis as well that may exceed the limitations or, by necessity, the functional ease of doing it otherwise. Also, what is our optimal format for ingestion? I guess it's probably markdown. Is that also for our metadata document? What is the content of that metadata document and investigate what other approaches using this dual-pronged method involve? This approach will be foundational for our use. It will include a list of all the different tools that are needed by the agent, specifically addressing every single document type that we anticipate needing to process and those which maybe we haven't even found yet but maybe we will in the future. Go online and search for additional document types, as my list, although comprehensive, may not be everything out there. There's probably some more ideal document types that you can find to add to our list of procedures. I think we'll probably formalize this into an MCP server architecture where the RAG agent will query a sub-agent who will know the specific structure for each of our ingestion documents. He'll ask, "Okay, it's a PDF. Ask the PDF agent." The PDF agent will come back and tell detailed descriptions of how to apply our methodology to that specific document. Unless this is not necessary, propose an alternative, but I think this is probably the best approach. That way, the context window of the primary agent is not massively exceeded on our initial request. This division of labor can be applied further towards various methods of different screenshots because we're going to have screenshots, we're going to have blogs, chat logs, YouTube video histories, file logs, data on file creation, file names, time that files were worked on, durations, time of video being watched, basically every scrap of data that we can pull out of this thing we want tagged. I don't know, and we'll see how it could be done without a metadata approach. So let me know how that works.</p>
            <p>It's also important that we process our existing Obsidian document catalog. We have approximately 300 documents that we've produced in the last two weeks since Obsidian was implemented on the system. Additionally, we have 600 Apple Notes, which were ingested in HTML format. Although that kind of broke some things. It didn't break others. We can re-import those again if that provides us with additional contextual metadata information or we can just revise our existing content. I also have Discord chat logs that I imported into the database. I did that before I knew all that we would have to process it first. So that will probably necessitate extraction and then analysis and re-implementation. Finally, I need some advanced procedures prepared for YouTube Takeout data provided by Google. This will include subscription data as well. The videos need to be, the logs need to be comprehensively analyzed in a procedural approach beginning with analysis of the content of the video first and general ingestion. Subsequently, when CPU and usage limits are acceptable, the agent will be requested to individually access all of the YouTube video pages associated with the watched records. So, we can gather a transcript, compile an analysis from this transcript of the content as well as any functional data patterns, schemas, code, and other structural data that may be described from the video. The data is processed in a non-relational database while the codified elements of our research are ingested into a relational database. This allows us to have a database which scales with the number of objects found as far as analysis and structural pattern identification is considered as well as a relational database for finding file names, topics, categories, metadata, time and watch information, duration, etc. And then a nested set of joined relational databases and then the associated non-relational database for structures that can vary in quantity. All this needs to be cohesively developed with our agentic multi-pronged approach with agents for describing our specific file type ingestion methods, as well as for descriptive elements when ingesting textual data like this is a record of my chat with AI on this date, or this is a record of when I was on the phone with so-and-so, or whatever, this is my text chat references. Also, prepare for the ability to ingest Twitter/X information, if necessary, RSS feeds, chat data from Telnet or other online chat services that have specific formats to their output. I'm thinking IRC off the top of my head, but there's probably others. We can do different types of YouTube channels; I already listed out documentaries, and we probably can have instructional videos, we can have Twitch streams, we can have product evaluations, we can have news articles, historical data, testing data; there's all sorts of sites where people test things against other things, all that kind of stuff, we need a strategy individualized for each of these. Right now, we just need the topics, and then later we'll go in and make these unique, uniquely formatted elements. Although we do require two to three examples for every single category and topic that we've discovered, otherwise, since we're at it, we might as well get something down on paper, and then the revision process will be easier and more functional.</p>
            <p>Essentially, this will culminate in the output of a comprehensive RAG strategy document. A document detailing the specific implementation of our strategy as pertaining to several specific file types. This document will be extended upon later and is generated as a production guide so that refinement can be done. Initial articles currently in production can be processed, and during the development and further creation and refinement of our RAG strategy, we aren't held up by the fact that we can't process anything. Also, in addition to those two documents, a document detailing the setup and implementation process for creating our multi-agent RAG agent approach is needed. This will define specifically the prompting characteristics for each RAG agent along with the tools that they will use; research on existing MCP server capabilities as we can use those as well. Our agent has the MCP tools listed at the bottom of this document, so you can refer to those initially in your ingestion protocols for ascertaining file type data, creation data, metadata, all that. We're also going to be creating a dual file meta tag format. This will be placed in a subdirectory within our Obsidian vault, so .metadata maybe, and then file format for our metadata needs. Additionally, I think we'll probably have several relational databases and non-relational databases, details, specifically the schemas for those databases, and how their implementation will interact with our existing Obsidian infrastructure will probably need some good Obsidian extensions as well. I know there's one that enables database techniques to be used within Obsidian libraries. Evaluate if that's an appropriate usage, and if we need that or not, and do the same with other extensions for Obsidian for auto-encoding, chunking, and processing. Finally, we'll need a comprehensive methodology for utilizing the above-defined functional structure/agentic multi-agent behavioral matrix so that we can use it to its most capable forms. This element will function as an initial usage guide for the software that we defined above. In the functional definitions are implementation procedure, how-to-use document, and will offer key insights into the dual-pronged multi-agentic approach, as well as the dual-element metadata implementation along and our database/implementation procedures. We probably will also need some code, so we'll require administration code, code for utilization and ingestion, code for obtaining and isolating and researching how to interact with our specific data structures, and we'll probably set this all up ultimately as an MCP server, and that MCP server will then have the sub-agents underneath it so that we'll be in a chat or something, and then we can just paste a document into the agent responsible for implementing our MCP procedure; that agent can then parse and process the document according to our document rules and create the metadata file, perform functional and thematic analysis upon the content as it's discovered, evaluate and extract data sets, forms, and patterns, and store said patterns in a relational database associated with the content source. So that later retrieval is facilitated along with said already included metadata like file name, creation date, modification date, size, and whatnot. If you can find a more comprehensive and more useful structure for doing this job already in use, please direct me towards that. If there's nothing that does everything we have described, at least as good or not better than what we're doing, then implement the plan, and we'll just do it ourselves because, you know, there's no sense in handicapping ourselves from the get-go. Proper creation and design of the MCP server prior to implementation is crucial.</p>
        </div>

        <div class="ai-response">
            <h2>GEMINI DEE(R)P RESEARCH Response</h2>
            <p>This is the current plan. What changes do you want to make?</p>
            <p>(1) Analyze the attached document 'claude html output in text form.txt' and the user's detailed query to synthesize a complete list of requirements for the RAG and agentic search system. Extract key principles, challenges, and specific user needs, such as handling AI-generated artifacts and email-compatible formatting.</p>
            <p>(2) Develop a holistic strategy for ingesting and converting a wide array of data types (text, code, multimedia, structured data, chat logs, web content) into a unified, clean markdown format suitable for RAG processing.</p>
            <p>(3) Design a detailed framework for document chunking and metadata association, including a multi-layered chunking methodology with context-aware overlapping and a dual-file system pairing each document with a comprehensive metadata file.</p>
            <p>(4) Create a protocol for analyzing non-textual content, including generating textual descriptions for visual media (images, charts) and transcribing audio/video, defining optimal system prompts for the specialized agents performing these tasks.</p>
            <p>(5) Design a multi-agent architecture for the pipeline, defining the roles of a primary orchestrator and specialized sub-agents for each data type (e.g., PDF Processor, Image Analyzer, YouTube Scraper), outlining their interaction via an MCP server model.</p>
            <p>(6) Propose a hybrid database architecture, including a relational schema for structured metadata and a non-relational schema for variable extracted data (code, patterns), and plan its integration with the user's Obsidian vault.</p>
            <p>(7) Create a step-by-step guide for implementing the system using Visual Studio Code and Homebrew, including scripts for automation and instructions for processing the user's existing data from Obsidian, Apple Notes, and Google Takeout.</p>
            <p>(8) Synthesize all findings into a set of final deliverables: a general RAG strategy document, a preliminary prompt for immediate use, a detailed user guide, and an appendix for user-specific customizations like the source icon reformatting.</p>
        </div>

        <div class="user-prompt">
            <h2>User Prompt</h2>
            <p>Perfect. Pay special attention to the architectural design of the setup with its multi-pronged multi-agent ingestion framework, the dual file markdown format of markdown and metadata format for file ingestion, and the multi-database contextual and thematic data analysis and retrieval. Pay special attention to the extraction of functional elements from our data, such as code, prompt tags, lists, instructions, patterns, schematics, etc. Those are what we're going to be placing in our non-relational database, and so that dual-pronged database approach, it's important that you specifically define how the database interacts with the files, because we'll have the file being ingested, the metadata file also ingested, I think, unless that should be in the database as well. Maybe everything just goes in the database. That's what I'm not sure about. Also, we need a cohesive reference guide in addition to our foundational document that strictly defines the specific implementations of our strategy in respect to all of our data types. While that's beyond the current scope, we do need at least two or three example descriptions for certain file types and use cases. One or two for online files, one for all the file types will require one or two examples of how to process them, because we're going to have Word documents that are videos, Word documents that are plays, Word documents that are presentations, and so we're going to have a specific use case for all of those, but fundamentally just for Word documents will require one. For the primary, say, top 50 encountered data types, that's important to be associated with our foundational document and will be the additional reference data set that the agent behavior will then reference and return to the primary user when they request the procedural guideline for the data set that they have or the data that they're ingesting currently. Additionally to that agent, the return data in that manner, additional agents might be able to provide contextual data on the architecture of the system or potentially retrieve data directly from the system that may aid in the processing and parsing of other files. The data structures that we extract, those might be useful as well. We want to preliminarily propose and allow for as fast an implementation as possible of a reflective, our data set is going to get better with time, iterative approach to refinement, so that we can constantly refer to our founding documents, produce data sets with them. This will necessitate Git version implementation, so that our specific contextual language can then be processed further. Additionally, consider in the context of eventual studies into the context degradation of AI interfaces. I will provide additional documentation for that, but it's an important research phase that we're going to be having. And so anything that we can do now to prepare our data properly to analyze and get ready for that analysis will be greatly appreciated. For this end, that's why it's so important that language model conversations get properly parsed so that data can be extracted from those on the functionality and current state of development or corruption that the context window for that language model is experiencing.</p>
        </div>

        <div class="ai-response">
            <h2>GEMINI DEE(R)P RESEARCH Response</h2>
            <p>(1) Analyze the user's requirements and the 'claude html output in text form.txt' to establish a foundation, paying special attention to the multi-agent architecture, dual-database model, and the need to prepare data for future AI context degradation analysis.</p>
            <p>(2) Design the core system architecture, detailing the multi-agent ingestion framework (orchestrator and specialized sub-agents). Define the data flow from raw file to a dual-file format (markdown content file and a separate metadata file).</p>
            <p>(3) Specify the dual-database model: a relational database for ingesting the metadata files (for context, file relationships, and searchable tags) and a non-relational database for storing extracted functional elements (code, schematics, prompts, patterns).</p>
            <p>(4) Develop detailed protocols for extracting functional elements from all content types. Create specific procedures for parsing AI conversation logs to isolate and tag data points relevant to context window state and degradation.</p>
            <p>(5) Plan the creation of a comprehensive, standalone 'Reference Guide'. This guide will detail the specific processing steps for the top 50 anticipated data types, providing 2-3 concrete examples for each to be used by an agent to instruct the user.</p>
            <p>(6) Define the agentic interaction model, where a primary agent uses the 'Reference Guide' to provide users with processing instructions, and sub-agents can query the databases to retrieve architectural information or existing data patterns to aid in new file ingestion.</p>
            <p>(7) Create a step-by-step implementation plan using Visual Studio Code and Homebrew. This plan must include setting up Git for version control of all strategy documents and configurations to enable an iterative refinement process.</p>
            <p>(8) Synthesize all findings into a final set of deliverables: the foundational architecture document, the separate 'Reference Guide', a user manual for the agentic system, and a preliminary prompt for immediate use.</p>
        </div>

        <div class="user-prompt">
            <h2>User Prompt</h2>
            <p>The first was submitted with the complete guide to RAG implementation, RAG implementation beyond simple chunking, and the Claude One document, I believe. Also, the Claude HTML output in text form. Also, the AI document on conversionstrategy.markdown.</p>
            <p>Second part was provided with the Part 1 formal refined mathematical framework MD document, the Part 3 initial draft of the research paper MD document, crafting my ideal environment document EMT model document.</p>
            <p>Please analyze the above document transcription and the associated uploaded files. I was creating a deep research query for the AI. However, I feel that the context window priming utilized by the deep research tool may have simplified my initial contextual request for an in-depth comprehensive framework to be developed from the above resources to get developed. The research is essential for comprehensively ascertaining that the methods and practices that we propose are unique and novel and warrant an in-depth computationally intensive approach. However, should alternative data prove otherwise, it's possible that we could instead adopt a project or method proposed by other researchers. Please create or conduct a preliminary investigation to ascertain if indeed our proposal is sufficiently unique to warrant this behavior. First, synthesize my words down into a comprehensive mandate with all content present. However, there's numerous instances of repetition and verbal pausing or improper formatting; voice transcription improperly recorded. Fix these and prepare a unified foundational document from the above system prompts that will then be used for investigation into the feasibility of using other projects for the intended use case. And if needed, the foundational documents necessary for creating the project as described above, essentially synthesize and combine all of the thoughts into a cohesive whole, make sure nothing gets forgotten. Double-check your work after you've done this the first time to ensure that nothing was omitted or misattributed during the evaluation analysis phase, then give an initial assessment followed by either a recommendation of which project to utilize or the nested document set creation descriptions that will ultimately make the body of this project. This is the reference manual and foundational description or technical schema specific to every individual file type and use case, our agentic interactive model along with specific code for implementing the model. First, this is just an agent prompt defining the role that will be associated with given tool use instances. And potentially another specialized agentic prompt for use with other tools, not such as the hard drive interaction tool, the internet search tool, the database query tool, the sequential thought tool, etc. All these tools should have specific agent prompts specialized for use cases implemented. Additionally, propose the creation of a usage document that defines all the usage document and then we also need an implementation document on how to set the whole thing up, detailed instructions on that, detailed instructions on how to use a document, and once we've done it. And then finally, an overview document that describes the general status of our conceptual framework and project, as well as provides this with, this will be the document that's utilized for ingestion of the currently in-development pipeline documents. There's about 30 documents in the pipeline now that require immediate markdown association. Make sure that the metadata is properly described and done properly. I don't know if the metadata should go in a separate file. If that file should be JSON or whatever, markdown, JSON, CSV, who knows what about our database files, what format should those ones be in. Is everything just in the database? Think about these framework ideas foundationally and fundamentally prior to performing your search and then search for the most similar projects out there, see what processes, if there are any, if our project is unique or not. And then, if it is unique, get the best ideas from all those projects so that we can implement them in our then-revised second version of all these described documentations. You basically have the idea here. My thought was that the deep research tool was excessively focused and directed towards search rather than synthesis. And the essential elements may have been eliminated from that deep research search query; provide a more comprehensively focused deep research query that we can provide to that tool after the completion of all other tasks. And use the two example prompts from the deep research tool responding to our suggestions as data for the length and format of your deep research question as you will want to duplicate this format exactly as that will greatly aid in the proper application of our directives and commands.</p>
        </div>
    </div>
</body>
</html>