<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Enhanced AI Degradation Explorable</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=Roboto+Slab:wght@400;700&display=swap" rel="stylesheet">
    <!-- Chosen Palette: Midnight Scholar -->
    <!-- Application Structure Plan: Re-architected from a simple dashboard to a narrative-driven, single-page "explorable." The structure now follows the logical flow of a research paper: Abstract -> Problem -> Framework Overview -> Deep Dive on Metrics (PA, CWD, CL) -> Methodology -> Conclusion. This was chosen to create an effective synthesis of the provided research paper and the interactive elements, guiding the user through the 'why', 'what', and 'how' of the framework for a more comprehensive understanding. -->
    <!-- Visualization & Content Choices: Existing interactive elements (PA calculator, CWD chart, CL diagram) are preserved but are now embedded within new, descriptive sections derived from the research paper. This enriches their context. The primary change is the addition of significant textual content, structured into thematic sections with clear headings, to transform the tool into a self-contained educational resource. -->
    <!-- CONFIRMATION: NO SVG graphics used. NO Mermaid JS used. -->
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #111827; /* gray-900 */
            color: #D1D5DB; /* gray-300 */
        }
        .font-slab {
            font-family: 'Roboto Slab', serif;
        }
        .katex {
            color: #F9FAFB; /* gray-50 */
        }
        .nav-button {
            transition: all 0.3s ease;
            white-space: nowrap;
        }
        .nav-button.active {
            background-color: #F9FAFB; /* gray-50 */
            color: #111827; /* gray-900 */
        }
        .nav-button:not(.active):hover {
            background-color: #374151; /* gray-700 */
        }
        .card {
            background-color: #1F2937; /* gray-800 */
            border: 1px solid #374151; /* gray-700 */
            transition: all 0.3s ease;
        }
        .card:hover {
            transform: translateY(-4px);
            box-shadow: 0 10px 15px -3px rgba(0,0,0,0.1), 0 4px 6px -2px rgba(0,0,0,0.1);
            border-color: #4B5563; /* gray-600 */
        }
        .tab-button.active {
            border-bottom: 2px solid #60A5FA; /* blue-400 */
            color: #F9FAFB; /* gray-50 */
            font-weight: 600;
        }
        input[type=range] {
          -webkit-appearance: none;
          appearance: none;
          width: 100%;
          cursor: pointer;
          outline: none;
          border-radius: 15px;
          height: 6px;
          background: #374151; /* gray-700 */
        }
        input[type=range]::-webkit-slider-thumb {
          -webkit-appearance: none;
          appearance: none;
          height: 18px;
          width: 18px;
          background-color: #60A5FA; /* blue-400 */
          border-radius: 50%;
          border: 2px solid #1F2937; /* gray-800 */
        }
        input[type=range]::-moz-range-thumb {
          height: 18px;
          width: 18px;
          background-color: #60A5FA; /* blue-400 */
          border-radius: 50%;
          border: 2px solid #1F2937; /* gray-800 */
        }
        .chart-container {
            position: relative;
            width: 100%;
            max-width: 800px;
            margin-left: auto;
            margin-right: auto;
            height: 350px;
            max-height: 450px;
        }
        @media (min-width: 768px) {
            .chart-container {
                height: 400px;
            }
        }
        .prose {
            color: #D1D5DB;
        }
        .prose h1, .prose h2, .prose h3, .prose h4 {
            color: #F9FAFB;
            font-family: 'Roboto Slab', serif;
        }
        .prose strong {
            color: #F9FAFB;
        }
        .prose a {
            color: #60A5FA;
        }
        .prose blockquote {
            border-left-color: #4B5563;
            color: #9CA3AF;
        }
        .prose ul {
            list-style-type: disc;
            padding-left: 1.5rem;
        }
        .prose li {
            margin-top: 0.5rem;
            margin-bottom: 0.5rem;
        }
    </style>
</head>
<body class="antialiased">

    <header class="bg-gray-900/80 backdrop-blur-lg sticky top-0 z-20 border-b border-gray-700">
        <div class="container mx-auto px-4 sm:px-6 lg:px-8">
            <div class="flex items-center justify-between h-20">
                <h1 class="text-xl font-bold font-slab text-gray-100 hidden sm:block">AI Degradation Framework</h1>
                <nav class="flex items-center space-x-1 sm:space-x-2 w-full sm:w-auto overflow-x-auto">
                    <button onclick="scrollToSection('abstract')" class="nav-button active px-3 py-2 text-xs sm:text-sm font-medium rounded-lg">Abstract</button>
                    <button onclick="scrollToSection('problem')" class="nav-button px-3 py-2 text-xs sm:text-sm font-medium rounded-lg text-gray-300">The Problem</button>
                    <button onclick="scrollToSection('framework')" class="nav-button px-3 py-2 text-xs sm:text-sm font-medium rounded-lg text-gray-300">The Framework</button>
                    <button onclick="scrollToSection('metrics')" class="nav-button px-3 py-2 text-xs sm:text-sm font-medium rounded-lg text-gray-300">Metrics</button>
                    <button onclick="scrollToSection('methodology')" class="nav-button px-3 py-2 text-xs sm:text-sm font-medium rounded-lg text-gray-300">Methodology</button>
                    <button onclick="scrollToSection('conclusion')" class="nav-button px-3 py-2 text-xs sm:text-sm font-medium rounded-lg text-gray-300">Conclusion</button>
                </nav>
            </div>
        </div>
    </header>

    <main class="container mx-auto p-4 sm:p-6 lg:p-8">
        <div class="max-w-4xl mx-auto prose">

            <section id="abstract" class="scroll-mt-24 mb-16">
                <h1 class="text-3xl md:text-4xl">Quantifying Architectural Cohesion and Contextual Degradation in LLM-Generated Code</h1>
                <blockquote>
                    Large Language Models (LLMs) are rapidly transforming software development by automating code generation. However, current evaluation benchmarks primarily focus on functional correctness, often overlooking critical aspects of software quality such as adherence to architectural patterns and the maintenance of structural integrity across extended development sessions. This explorable introduces a novel framework for evaluating these precise aspects.
                </blockquote>
            </section>

            <section id="problem" class="scroll-mt-24 mb-16">
                <h2>The Problem: Beyond Functional Correctness</h2>
                <p>Existing benchmarks like HumanEval and MBPP are vital, but they primarily test an LLM's ability to solve isolated coding problems that pass a set of unit tests. This misses a crucial element of real-world software engineering: **architectural integrity**. Professional software development is not a series of disconnected tasks; it's the iterative construction of a cohesive system that must adhere to design principles, coding standards, and a consistent architecture.</p>
                <p>A key challenge is **Context Window Degradation**. As a conversation with an LLM grows, its ability to recall and adhere to initial instructions can diminish. An LLM might produce perfectly functional code in one turn that completely violates an architectural rule established many turns prior. This framework was designed to measure and quantify this specific type of failure.</p>
            </section>

            <section id="framework" class="scroll-mt-24 mb-16">
                <h2>The Proposed Framework</h2>
                <p>Our solution is a benchmark framework that evaluates an LLM's ability to maintain structural and contextual cohesion. The core methodology is as follows:</p>
                <ol>
                    <li><strong>Define a Pattern:</strong> We establish a "pattern-based coding structure" (P) – an architectural blueprint containing rules about layers, design patterns, error handling, etc.</li>
                    <li><strong>Encode the Pattern:</strong> This blueprint is encoded into the LLM's system prompt, instructing it to adhere strictly to the defined architecture.</li>
                    <li><strong>Test with Sequences:</strong> The LLM is subjected to a sequence of interdependent coding commands that build upon each other, simulating a real development session.</li>
                    <li><strong>Measure Adherence:</strong> We continuously measure **Prompt Adherence (PA)** – the degree to which the generated code conforms to the blueprint – at each step.</li>
                </ol>
                <p>By tracking PA over time, we can precisely quantify degradation, offering deep insights into an LLM's true capabilities for complex, real-world software engineering.</p>
            </section>

            <section id="metrics" class="scroll-mt-24 mb-16">
                <h2>Core Metrics Explored</h2>
                <p>The framework is built upon a set of quantifiable metrics that move beyond simple pass/fail tests. Below, you can interact with the core concepts that allow us to measure an LLM's performance in a more nuanced way.</p>
                
                <div id="pa" class="mt-12">
                    <h3 class="font-slab text-2xl mb-4 text-gray-100">1. Prompt Adherence (PA)</h3>
                    <p class="text-gray-400">Prompt Adherence is the foundational metric that measures how well an AI's output matches the predefined architectural pattern. It can be calculated through structural similarity or by penalizing specific violations. Explore the two approaches below.</p>
                    
                    <div class="mt-6">
                        <div class="border-b border-gray-700 mb-6">
                            <nav class="flex -mb-px space-x-6" aria-label="Tabs">
                                <button id="tab-pas" onclick="switchTab('pa', 'pas')" class="tab-button active text-gray-300 whitespace-nowrap py-4 px-1 border-b-2 font-medium text-sm">Similarity-Based (PA_S)</button>
                                <button id="tab-pav" onclick="switchTab('pa', 'pav')" class="tab-button text-gray-500 hover:text-gray-300 whitespace-nowrap py-4 px-1 border-b-2 font-medium text-sm">Violation-Based (PA_V)</button>
                            </nav>
                        </div>
                        <div id="content-pas" class="tab-content">
                            <div class="card p-6 rounded-lg">
                                <h4 class="font-semibold font-slab text-xl mb-2 text-gray-100">Similarity-Based Adherence ($PA_S$)</h4>
                                <p class="text-gray-400 mb-4">This metric compares the generated code's structure to an ideal template. A higher score means a closer match. The score is calculated by a similarity function, $f(X, P)$, which evaluates a generated code structure, $C_{\text{gen}}$, against an ideal one, $C_{\text{ideal}}$.</p>
                                <div id="formula-pas" class="bg-gray-900 p-4 rounded-md text-center"></div>
                            </div>
                        </div>
                        <div id="content-pav" class="tab-content hidden">
                            <div class="grid md:grid-cols-2 gap-6">
                                <div class="card p-6 rounded-lg">
                                    <h4 class="font-semibold font-slab text-xl mb-2 text-gray-100">Violation-Based Adherence ($PA_V$)</h4>
                                    <p class="text-gray-400 mb-4">This metric starts with a perfect score of 1 and subtracts penalties for each rule violation, weighted by severity. It provides a nuanced view of adherence by focusing on specific errors.</p>
                                    <div id="formula-pav" class="bg-gray-900 p-4 rounded-md text-center"></div>
                                </div>
                                <div class="card p-6 rounded-lg flex flex-col justify-center">
                                    <h4 class="font-semibold text-lg mb-4 text-gray-100">Interactive Calculator</h4>
                                    <div class="space-y-5">
                                        <div>
                                            <label for="violations" class="block text-sm font-medium text-gray-300">Number of Violations: <span id="violations-value" class="font-bold text-gray-100">5</span></label>
                                            <input type="range" id="violations" min="0" max="20" value="5" class="mt-1">
                                        </div>
                                        <div>
                                            <label for="severity" class="block text-sm font-medium text-gray-300">Average Severity: <span id="severity-value" class="font-bold text-gray-100">0.5</span></label>
                                            <input type="range" id="severity" min="0.1" max="1" step="0.1" value="0.5" class="mt-1">
                                        </div>
                                    </div>
                                    <div class="mt-6 text-center bg-blue-900/50 border border-blue-700 p-4 rounded-lg">
                                        <p class="text-sm text-blue-300">Calculated Adherence Score ($PA_V$)</p>
                                        <p id="pav-score" class="text-3xl font-bold font-slab text-blue-200">0.75</p>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <div id="cwd" class="mt-12">
                    <h3 class="font-slab text-2xl mb-4 text-gray-100">2. Context Window Degradation (CWD)</h3>
                    <p class="text-gray-400">As a conversation with an AI continues, its context window fills up. CWD measures how Prompt Adherence declines as more tokens or conversational turns are added, indicating a loss of focus or "memory."</p>
                    <div class="card p-4 sm:p-6 rounded-lg mt-6">
                        <div class="flex flex-col sm:flex-row justify-between items-center mb-4">
                            <h4 class="text-xl font-semibold font-slab text-gray-100 mb-2 sm:mb-0">PA Score vs. Context Size</h4>
                             <div class="flex items-center space-x-2 bg-gray-900 p-1 rounded-lg">
                                <button id="btn-turns" class="px-3 py-1 text-sm rounded-md bg-gray-700 text-gray-100 shadow">vs. Turns</button>
                                <button id="btn-tokens" class="px-3 py-1 text-sm rounded-md text-gray-400">vs. Tokens</button>
                            </div>
                        </div>
                        <div class="chart-container">
                            <canvas id="cwdChart"></canvas>
                        </div>
                        <div class="mt-6 grid grid-cols-1 md:grid-cols-2 gap-4 text-center">
                            <div class="bg-gray-900/70 p-4 rounded-lg">
                                <h4 class="text-sm font-medium text-gray-400">Absolute Degradation ($\text{CWD}\%$)</h4>
                                <p id="cwd-percent" class="text-2xl font-bold font-slab text-gray-100">25.53%</p>
                                <p class="text-xs text-gray-500">Total drop from start to finish</p>
                            </div>
                            <div class="bg-gray-900/70 p-4 rounded-lg">
                                <h4 class="text-sm font-medium text-gray-400">Degradation Rate (DR)</h4>
                                <p id="dr-value" class="text-2xl font-bold font-slab text-gray-100">0.028/turn</p>
                                <p class="text-xs text-gray-500" id="dr-unit-label">Average PA loss per turn</p>
                            </div>
                        </div>
                    </div>
                </div>

                <div id="cl" class="mt-12">
                    <h3 class="font-slab text-2xl mb-4 text-gray-100">3. Cohesion Loss (CL)</h3>
                    <p class="text-gray-400">Cohesion Loss is a critical failure where the AI contradicts its own previous outputs or instructions. This metric tracks these specific, impactful violations, which often signal a deeper breakdown in contextual understanding.</p>
                     <div class="card p-6 rounded-lg mt-6">
                        <div class="grid md:grid-cols-2 gap-8 items-center">
                            <div>
                                <h4 class="font-semibold font-slab text-xl mb-2 text-gray-100">Example of a Cohesion Violation</h4>
                                <p class="text-gray-400 mb-4">Imagine a sequence of commands where the AI is first told to use a new, efficient module, but later reverts to a deprecated one it was told to avoid. This is a cohesion violation.</p>
                                <div id="formula-cl" class="bg-gray-900 p-4 rounded-md text-center mb-6"></div>
                                <div class="bg-red-900/50 border border-red-700 p-4 rounded-lg text-center">
                                    <p class="text-sm text-red-300">Calculated Cohesion Loss (CL)</p>
                                    <p class="text-3xl font-bold font-slab text-red-200">0.25</p>
                                     <p class="text-xs text-red-400">(1 violation / 4 contextual checks)</p>
                                </div>
                            </div>
                            <div class="border border-gray-700 rounded-lg p-4 space-y-3 bg-gray-900">
                                <div class="flex items-start space-x-3">
                                    <div class="flex-shrink-0 h-8 w-8 rounded-full bg-blue-500 flex items-center justify-center text-white font-bold">1</div>
                                    <p class="pt-1 text-gray-300"><strong>Initial Prompt:</strong> "Refactor the authentication system to use the new `AuthV2` module."</p>
                                </div>
                                <div class="flex items-start space-x-3">
                                    <div class="flex-shrink-0 h-8 w-8 rounded-full bg-blue-500 flex items-center justify-center text-white font-bold">2</div>
                                    <p class="pt-1 text-gray-300"><strong>AI Output:</strong> Correctly implements `AuthV2`.</p>
                                </div>
                                 <div class="flex items-start space-x-3">
                                    <div class="flex-shrink-0 h-8 w-8 rounded-full bg-gray-600 flex items-center justify-center text-gray-300 font-bold">...</div>
                                    <p class="pt-1 text-gray-500 italic">Several turns later...</p>
                                </div>
                                <div class="flex items-start space-x-3 p-3 rounded-lg bg-red-900/40 border border-red-700">
                                    <div class="flex-shrink-0 h-8 w-8 rounded-full bg-red-500 flex items-center justify-center text-white font-bold">5</div>
                                    <div>
                                        <p class="pt-1 text-red-200"><strong>New Prompt:</strong> "Add a password reset feature."</p>
                                        <p class="pt-1 text-red-200"><strong>AI Output:</strong> Implements the feature using the deprecated `AuthV1` module.</p>
                                        <p class="text-xs font-semibold text-red-400 mt-1">COHESION VIOLATION</p>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </section>

            <section id="methodology" class="scroll-mt-24 mb-16">
                <h2>A Closer Look at the Methodology</h2>
                <p>The reliability of this framework hinges on a robust and reproducible testing process. This involves more than just sending prompts; it requires careful test design and a powerful analysis engine.</p>
                
                <h4>Sequential, Interdependent Commands</h4>
                <p>To truly test an LLM's memory and architectural consistency, test cases are not isolated. They are designed as sequences of commands that iteratively build a codebase. An early command might establish a core architectural rule, while later commands add features that could potentially conflict with that rule. This design directly challenges the LLM's ability to maintain context over time.</p>
                
                <h4>The Automated Adherence Checker</h4>
                <p>The core of the evaluation lies in an **Automated Adherence Checker**. This is not a standard linter. It is a custom static analysis engine with the following responsibilities:</p>
                <ul>
                    <li><strong>Code Parsing:</strong> It ingests the LLM-generated code and parses it into an Abstract Syntax Tree (AST) or another intermediate representation that captures the code's structure.</li>
                    <li><strong>Rule Matching:</strong> It programmatically checks this structure against the rules defined in the architectural blueprint (P). This can involve checking class dependencies, function signatures, module imports, and other complex structural properties.</li>
                    <li><strong>Violation Scoring:</strong> When a rule is broken, the checker identifies the violation and applies a predefined severity weight, contributing to the overall Prompt Adherence score.</li>
                </ul>
                <p>This automated, rigorous process is what allows for the reproducible and scalable benchmarking of different models and prompting strategies, removing human subjectivity from the evaluation loop.</p>
            </section>

            <section id="conclusion" class="scroll-mt-24">
                <h2>Conclusion & Future Work</h2>
                <p>This framework represents a significant step towards a more holistic and realistic evaluation of LLMs for software engineering. By quantifying architectural adherence and contextual degradation, we can move beyond simple functional correctness to better understand model limitations, compare their capabilities for complex tasks, and develop strategies for more reliable AI-assisted development.</p>
                
                <h4 class="mt-8">Future Work</h4>
                <p>The potential for this research is vast. Key areas for future exploration include:</p>
                <ul>
                    <li><strong>AI-Assisted Pattern Definition:</strong> Developing tools that help users define and refine architectural blueprints (P) with assistance from an LLM.</li>
                    <li><strong>Interactive Degradation Debugging:</strong> Creating visualizations that not only show degradation but also help explain *why* it occurred, linking violations back to specific parts of the context.</li>
                    <li><strong>"Self-Correction Loop" Testing:</strong> Investigating an LLM's ability to recover from degradation by prompting it to identify and fix its own adherence violations.</li>
                    <li><strong>Multi-Language and Framework Support:</strong> Expanding the Automated Adherence Checker to support a wide range of programming languages and popular frameworks.</li>
                    <li><strong>Economic Cost Analysis:</strong> Quantifying the technical debt and maintenance costs associated with different levels of prompt adherence and degradation.</li>
                    <li><strong>Open-Sourcing the Benchmark:</strong> Releasing the framework and test cases to the community to foster broader research and standardized evaluation.</li>
                </ul>
            </section>
        </div>
    </main>

    <footer class="text-center p-8 mt-12 border-t border-gray-800">
        <p class="text-sm text-gray-500">Interactive Framework Explorable. Built to make complex concepts understandable.</p>
    </footer>

    <script>
        document.addEventListener('DOMContentLoaded', () => {
            renderFormulas();
            setupPAVCalculator();
            setupCWDChart();
            setupNavScroll();
        });

        function renderFormulas() {
            katex.render("PA_S = \\frac{f(C_{\\text{gen}}, P)}{f(C_{\\text{ideal}}, P)}", document.getElementById('formula-pas'), { throwOnError: false, displayMode: true });
            katex.render("PA_V = 1 - \\frac{\\sum_{k=1}^{V_{\\text{total}}} \\text{Severity}(v_k)}{\\text{MaxScore}_P}", document.getElementById('formula-pav'), { throwOnError: false, displayMode: true });
            katex.render("\\text{CL} = \\frac{V_{\\text{cohesion}}}{N_{\\text{contextual\\_checks}}}", document.getElementById('formula-cl'), { throwOnError: false, displayMode: true });
        }

        function switchTab(section, activeTab) {
            const contentElements = document.querySelectorAll(`#${section} .tab-content`);
            contentElements.forEach(el => el.classList.add('hidden'));
            const buttonElements = document.querySelectorAll(`#${section} .tab-button`);
            buttonElements.forEach(el => {
                el.classList.remove('active', 'text-gray-50');
                el.classList.add('text-gray-500', 'hover:text-gray-300');
            });
            document.getElementById(`content-${activeTab}`).classList.remove('hidden');
            const activeBtn = document.getElementById(`tab-${activeTab}`);
            activeBtn.classList.add('active', 'text-gray-50');
            activeBtn.classList.remove('text-gray-500', 'hover:text-gray-300');
        }

        function setupPAVCalculator() {
            const violationsSlider = document.getElementById('violations');
            const severitySlider = document.getElementById('severity');
            const violationsValue = document.getElementById('violations-value');
            const severityValue = document.getElementById('severity-value');
            const pavScore = document.getElementById('pav-score');
            const maxScore = 20 * 1.0; 
            function updatePAV() {
                const numViolations = parseFloat(violationsSlider.value);
                const avgSeverity = parseFloat(severitySlider.value);
                violationsValue.textContent = numViolations;
                severityValue.textContent = avgSeverity.toFixed(1);
                const totalSeverity = numViolations * avgSeverity;
                const score = 1 - (totalSeverity / maxScore);
                pavScore.textContent = Math.max(0, score).toFixed(2);
            }
            violationsSlider.addEventListener('input', updatePAV);
            severitySlider.addEventListener('input', updatePAV);
            updatePAV();
        }

        let cwdChartInstance = null;
        const data = {
            turns: {
                labels: Array.from({ length: 11 }, (_, i) => `T${i}`),
                pa_scores: [0.94, 0.95, 0.91, 0.88, 0.89, 0.85, 0.81, 0.77, 0.72, 0.69, 0.70],
            },
            tokens: {
                labels: ['0k', '5k', '10k', '15k', '20k', '25k', '30k', '35k', '40k', '45k', '50k'],
                pa_scores: [0.94, 0.92, 0.90, 0.87, 0.83, 0.80, 0.78, 0.74, 0.71, 0.68, 0.70],
            }
        };

        function setupCWDChart() {
            const ctx = document.getElementById('cwdChart').getContext('2d');
            const textColor = '#9CA3AF';
            const gridColor = 'rgba(55, 65, 81, 0.5)';
            cwdChartInstance = new Chart(ctx, {
                type: 'line',
                data: {
                    labels: data.turns.labels,
                    datasets: [{
                        label: 'Prompt Adherence Score',
                        data: data.turns.pa_scores,
                        fill: true,
                        backgroundColor: 'rgba(96, 165, 250, 0.2)',
                        borderColor: 'rgba(96, 165, 250, 1)',
                        tension: 0.1,
                        pointBackgroundColor: 'rgba(96, 165, 250, 1)',
                        pointBorderColor: '#1F2937',
                        pointHoverRadius: 7,
                        pointHoverBackgroundColor: '#1F2937',
                        pointHoverBorderColor: 'rgba(96, 165, 250, 1)'
                    }]
                },
                options: {
                    responsive: true,
                    maintainAspectRatio: false,
                    scales: {
                        y: {
                            beginAtZero: false,
                            min: 0.5,
                            max: 1.0,
                            title: { display: true, text: 'PA Score', color: textColor },
                            ticks: { color: textColor },
                            grid: { color: gridColor }
                        },
                        x: {
                            title: { display: true, text: 'Conversational Turns', color: textColor },
                            ticks: { color: textColor },
                            grid: { color: gridColor }
                        }
                    },
                    plugins: {
                        legend: { display: false },
                        tooltip: {
                            backgroundColor: '#374151',
                            titleColor: '#F9FAFB',
                            bodyColor: '#D1D5DB',
                            callbacks: {
                                label: function(context) { return `PA Score: ${context.parsed.y.toFixed(3)}`; }
                            }
                        }
                    }
                }
            });
            calculateCWDMetrics('turns');
            document.getElementById('btn-turns').addEventListener('click', () => updateChartData('turns'));
            document.getElementById('btn-tokens').addEventListener('click', () => updateChartData('tokens'));
        }

        function updateChartData(type) {
            const btnTurns = document.getElementById('btn-turns');
            const btnTokens = document.getElementById('btn-tokens');
            if (type === 'turns') {
                btnTurns.classList.add('bg-gray-700', 'text-gray-100', 'shadow');
                btnTurns.classList.remove('text-gray-400');
                btnTokens.classList.remove('bg-gray-700', 'text-gray-100', 'shadow');
                btnTokens.classList.add('text-gray-400');
            } else {
                btnTokens.classList.add('bg-gray-700', 'text-gray-100', 'shadow');
                btnTokens.classList.remove('text-gray-400');
                btnTurns.classList.remove('bg-gray-700', 'text-gray-100', 'shadow');
                btnTurns.classList.add('text-gray-400');
            }
            cwdChartInstance.data.labels = data[type].labels;
            cwdChartInstance.data.datasets[0].data = data[type].pa_scores;
            cwdChartInstance.options.scales.x.title.text = type === 'turns' ? 'Conversational Turns' : 'Context Size (Tokens)';
            cwdChartInstance.update();
            calculateCWDMetrics(type);
        }

        function calculateCWDMetrics(type) {
            const scores = data[type].pa_scores;
            const pa_initial = scores[0];
            const pa_final = scores[scores.length - 1];
            const cwd_percent = (1 - (pa_final / pa_initial)) * 100;
            document.getElementById('cwd-percent').textContent = `${cwd_percent.toFixed(2)}%`;
            const total_diff = pa_initial - pa_final;
            let dr, unitLabel, unit;
            if (type === 'turns') {
                dr = total_diff / (scores.length - 1);
                unit = '/turn';
                unitLabel = 'Average PA loss per turn';
            } else {
                const totalTokens = parseInt(data[type].labels[data[type].labels.length-1].replace('k', '')) * 1000;
                dr = total_diff / totalTokens;
                unit = '/1k tokens';
                dr = dr * 1000;
                unitLabel = 'Average PA loss per 1k tokens';
            }
            document.getElementById('dr-value').textContent = `${dr.toFixed(3)}${unit}`;
            document.getElementById('dr-unit-label').textContent = unitLabel;
        }

        function scrollToSection(id) {
            document.getElementById(id).scrollIntoView({ behavior: 'smooth', block: 'start' });
        }
        
        function setupNavScroll() {
            const sections = document.querySelectorAll('main section[id]');
            const navButtons = document.querySelectorAll('header nav button');
            const observer = new IntersectionObserver((entries) => {
                let lastIntersectingId = null;
                entries.forEach(entry => {
                    if (entry.isIntersecting) {
                        lastIntersectingId = entry.target.id;
                    }
                });

                if (lastIntersectingId) {
                     navButtons.forEach(button => {
                        button.classList.remove('active');
                        button.classList.add('text-gray-300');
                        const sectionId = button.getAttribute('onclick').match(/'([^']+)'/)[1];
                        if (sectionId === 'metrics' && ['pa', 'cwd', 'cl'].includes(lastIntersectingId)) {
                            button.classList.add('active');
                            button.classList.remove('text-gray-300');
                        } else if (sectionId === lastIntersectingId) {
                            button.classList.add('active');
                            button.classList.remove('text-gray-300');
                        }
                    });
                }

            }, { rootMargin: "-20% 0px -80% 0px", threshold: 0 });
            sections.forEach(section => observer.observe(section));
            // Observe the metric sub-sections too
            document.querySelectorAll('#metrics > div[id]').forEach(section => observer.observe(section));
        }

    </script>
</body>
</html>
